{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress TF logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Setting up GPU use explicitly to prevent initialization warnings\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress warning messages\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution2d(image: np.ndarray, kernel: np.ndarray, stride: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement 2D convolution operation from scratch using NumPy\n",
    "\n",
    "    Args:\n",
    "        image(np.ndarray): Input image/matrix\n",
    "        kernel (np.ndarray): Convolution kernel/filter\n",
    "        stride (int): Stride value, default is 1\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Resulting convolved matrix\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # Calculate output dimensions\n",
    "    output_height = ((image_height - kernel_height) // stride) + 1\n",
    "    output_width = ((image_width - kernel_width) // stride) + 1\n",
    "\n",
    "    # Initialize output matrix\n",
    "    output = np.zeros((output_height, output_width))\n",
    "\n",
    "    # Perform convolution\n",
    "    for i in range(0, image_height - kernel_height + 1, stride):\n",
    "        for j in range(0, image_width - kernel_width + 1, stride):\n",
    "            # Extract the current window\n",
    "            current_window = image[i:i+kernel_height, j:j+kernel_width]\n",
    "            # Perform element-wise multiplication and sum\n",
    "            output[i//stride, j//stride] = np.sum(current_window * kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Test our convolution function with an example\n",
    "test_matrix = np.array([\n",
    "    [45, 63, 27, 90, 34],\n",
    "    [36, 18, 81, 9, 87],\n",
    "    [9, 54, 72, 99, 56],\n",
    "    [83, 23, 12, 43, 54],\n",
    "    [27, 8, 19, 67, 69]\n",
    "])\n",
    "\n",
    "# Create a 3x3 box filter kernel (all elements = 1/9)\n",
    "box_kernel = np.ones((3, 3)) / 9\n",
    "\n",
    "# Apply convolution\n",
    "result = convolution2d(test_matrix, box_kernel)\n",
    "\n",
    "def display_convolution_result(original, kernel, result):\n",
    "    \"\"\"\n",
    "    Display the original matrix, kernel, and convolution result.\n",
    "    \"\"\"\n",
    "    print(\"Original Matrix:\")\n",
    "    print(original)\n",
    "    print(\"\\nKernel:\")\n",
    "    print(kernel)\n",
    "    print(\"\\nConvolution Result:\")\n",
    "    print(result)\n",
    "\n",
    "# Test our display function\n",
    "display_convolution_result(test_matrix, box_kernel, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('./data/moo_deng.jpg')\n",
    "\n",
    "def display_image(images, titles=None, figsize=(15, 5), cmaps=None):\n",
    "    \"\"\"\n",
    "    Display multiple images side by side with matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        images: Single image or list of images\n",
    "        titles: Optional list of titles for each image\n",
    "        figsize: Figure size (width, height)\n",
    "        cmaps: Single colormap or list of colormaps for single-channel images\n",
    "    \"\"\"\n",
    "    # Convert single image to list\n",
    "    if not isinstance(images, list):\n",
    "        images = [images]\n",
    "    \n",
    "    # Create default titles if none provided\n",
    "    if titles is None:\n",
    "        titles = [f'Image {i+1}' for i in range(len(images))]\n",
    "    elif isinstance(titles, str):\n",
    "        titles = [titles]\n",
    "    \n",
    "    # Handle colormap specification\n",
    "    if cmaps is None:\n",
    "        cmaps = ['gray'] * len(images)\n",
    "    elif isinstance(cmaps, str):\n",
    "        cmaps = [cmaps] * len(images)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=figsize)\n",
    "    # Convert single axis to list for consistent indexing\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Display each image\n",
    "    for ax, img, title, cmap in zip(axes, images, titles, cmaps):\n",
    "        if len(img.shape) == 3:\n",
    "            # Convert BGR to RGB for display\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img_rgb)\n",
    "        else:\n",
    "            # If grayscale, use specified colormap\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Let's examine the image properties\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"image data type: {img.dtype}\")\n",
    "print(f\"Min pixel value: {img.min()}\")\n",
    "print(f\"Max pixel value: {img.max()}\")\n",
    "\n",
    "# Display original image\n",
    "display_image(img, \"Original Image\")\n",
    "\n",
    "# Display color channels \n",
    "b, g, r = cv2.split(img)\n",
    "display_image([b, g, r], \n",
    "             titles=['Blue channel', 'Green channel', 'Red channel'], \n",
    "             figsize=(15, 5),\n",
    "             cmaps='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our numpy array (image) to a TensorFlow tensor\n",
    "img_tf = tf.convert_to_tensor(img)\n",
    "\n",
    "# Let's verify the conversion\n",
    "print(f\"Original numpy array type: {type(img)}\")\n",
    "print(f\"Original numpy array shape: {img.shape}\")\n",
    "print(f\"Original numpy array dtype: {img.dtype}\")\n",
    "print(\"\\n\")\n",
    "print(f\"TensorFlow tensor type: {type(img_tf)}\")\n",
    "print(f\"TensorFlow tensor shape: {img_tf.shape}\")\n",
    "print(f\"TensorFlow tensor dtype: {img_tf.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_box_kernel(size=3):\n",
    "    \"\"\"\n",
    "    Create a box filter kernel using TensorFlow.\n",
    "    \"\"\"\n",
    "    kernel = tf.ones((size, size)) / (size * size)\n",
    "    kernel = tf.expand_dims(tf.expand_dims(kernel, -1), -1)\n",
    "    return kernel\n",
    "\n",
    "def create_gaussian_kernel(size=3, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Create a Gaussian kernel using TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        size (int): Kernel size (should be odd)\n",
    "        sigma (float): Standard deviation of the Gaussian distribution\n",
    "    \"\"\"\n",
    "    # Create a coordinate grid\n",
    "    ax = tf.range(-size // 2 + 1.0, size // 2 + 1.0)\n",
    "    xx, yy = tf.meshgrid(ax, ax)\n",
    "\n",
    "    # Calculate the Gaussian kernel\n",
    "    kernel = tf.exp(-(xx**2 + yy**2)/ (2.0 * sigma**2))\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel = kernel / tf.reduce_sum(kernel)\n",
    "\n",
    "    # Expand dimensions for broadcasting\n",
    "    kernel = tf.expand_dims(tf.expand_dims(kernel, -1), -1)\n",
    "    return kernel\n",
    "\n",
    "def apply_filter(image, kernel):\n",
    "    \"\"\"\n",
    "    Apply a filter kernel to an image using TensorFlow convolution.\n",
    "    Handles both grayscale and color images.\n",
    "    \"\"\"\n",
    "    # Add batch dimension if not present\n",
    "    if len(image.shape) == 3:\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "    # Convert to float32 for computation\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # Apply filter to each channel separately\n",
    "    channels = tf.unstack(image, axis=-1)\n",
    "    filtered_channels = []\n",
    "\n",
    "    for channel in channels:\n",
    "        # Add channel dimension\n",
    "        channel = tf.expand_dims(tf.expand_dims(channel, 0), -1)\n",
    "        # Apply convolution\n",
    "        filtered = tf.nn.conv2d(channel, kernel, strides=1, padding='SAME')\n",
    "        filtered_channels.append(tf.squeeze(filtered))\n",
    "\n",
    "    # Stack channels back together\n",
    "    filtered_image = tf.stack(filtered_channels, axis=-1)\n",
    "\n",
    "    # Remove batch dimension and convert back to uint8\n",
    "    filtered_image = tf.squeeze(filtered_image)\n",
    "    fitlered_image = tf.clip_by_value(filtered_image, 0, 255)\n",
    "    filtered_image = tf.cast(filtered_image, tf.uint8)\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def unsharp_mask(image, kernel_size=3, amount=1.0):\n",
    "    \"\"\"\n",
    "    Apply unsharp masking to an image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image tensor\n",
    "        kernel_size: Size of the Gaussian kernel for blurring\n",
    "        amount: Strength of the sharpening effect\n",
    "    \"\"\"\n",
    "    # Create Gaussian kernel for blurring\n",
    "    gaussian_kernel = create_gaussian_kernel(kernel_size, sigma=1.0)\n",
    "\n",
    "    # Blur the image\n",
    "    blurred = apply_filter(image, gaussian_kernel)\n",
    "\n",
    "    # Calculate the mask (detail)\n",
    "    mask = tf.cast(image, tf.float32) - tf.cast(blurred, tf.float32)\n",
    "\n",
    "    # Add weighted mask to original image\n",
    "    sharpened = tf.cast(image, tf.float32) + amount * mask\n",
    "\n",
    "    # Clip values and convert back to uint8\n",
    "    sharpened = tf.clip_by_value(sharpened, 0, 255)\n",
    "    sharpened = tf.cast(sharpened, tf.uint8)\n",
    "\n",
    "    return sharpened\n",
    "\n",
    "# Apply all filters to our image\n",
    "box_filtered = apply_filter(img_tf, create_box_kernel(15))\n",
    "gaussian_filtered = apply_filter(img_tf, create_gaussian_kernel(15, 2.5))\n",
    "sharpened = unsharp_mask(img_tf, 15, 1.5)\n",
    "\n",
    "display_image([img_tf.numpy(), box_filtered.numpy(), gaussian_filtered.numpy(), sharpened.numpy()],\n",
    "             titles=[\"Original Image\", \"Box Filter\", \"Gaussian Filter\", \"Unsharp Masking\"],\n",
    "             figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sobel_kernels():\n",
    "    \"\"\"\n",
    "    Create Sobel kernels for x and y directions using TensorFlow.\n",
    "    \"\"\"\n",
    "    # Sobel kernel for horizontal edges\n",
    "    kernel_x = tf.constant([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    # Sobel kernel for vertical edges\n",
    "    kernel_y = tf.constant([\n",
    "        [-1, -2, -1],\n",
    "        [0, 0, 0],\n",
    "        [1, 2, 1]\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    # Expand dimensions for TF convolution\n",
    "    kernel_x = tf.expand_dims(tf.expand_dims(kernel_x, -1), -1)\n",
    "    kernel_y = tf.expand_dims(tf.expand_dims(kernel_y, -1), -1)\n",
    "    \n",
    "    return kernel_x, kernel_y\n",
    "\n",
    "def detect_edges(image):\n",
    "    \"\"\"\n",
    "    Detect edges in an image using the Sobel operator.\n",
    "\n",
    "    Args:\n",
    "        image: Input image tensor (BGR format)\n",
    "    Returns:\n",
    "        edge_magnitude: Compbined edge magnitude\n",
    "        edge_x: Horizontal edges\n",
    "        edge_y: Vertical edges\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if color image\n",
    "    if len(image.shape) == 3:\n",
    "        # Convert BGR to grayscale using standard weights\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        grayscale = 0.114 * image[..., 0] + 0.587 * image[..., 1] + 0.299 * image[..., 2]\n",
    "        grayscale = tf.expand_dims(grayscale, -1)\n",
    "\n",
    "    # Add batch dimension\n",
    "    grayscale = tf.expand_dims(grayscale, 0)\n",
    "\n",
    "    # Get Sobel kernels\n",
    "    kernel_x, kernel_y = create_sobel_kernels()\n",
    "\n",
    "    # Apply convolution for both directions\n",
    "    edge_x = tf.nn.conv2d(grayscale, kernel_x, strides=1, padding='SAME')\n",
    "    edge_y = tf.nn.conv2d(grayscale, kernel_y, strides=1, padding='SAME')\n",
    "\n",
    "    # Calculate edge magnitude\n",
    "    edge_magnitude = tf.sqrt(tf.square(edge_x) + tf.square(edge_y))\n",
    "\n",
    "    # Normalize to 0-255 range\n",
    "    edge_magnitude = tf.squeeze(edge_magnitude)\n",
    "    edge_magnitude = (edge_magnitude - tf.reduce_min(edge_magnitude)) / (tf.reduce_max(edge_magnitude) - tf.reduce_min(edge_magnitude)) * 255\n",
    "\n",
    "    # Convert back to uint8\n",
    "    edge_magnitude = tf.cast(edge_magnitude, tf.uint8)\n",
    "\n",
    "    return edge_magnitude, tf.squeeze(edge_x), tf.squeeze(edge_y)\n",
    "\n",
    "# Apply edge detection to our image\n",
    "edge_magnitude, edge_x, edge_y = detect_edges(img_tf)\n",
    "\n",
    "# Display the results\n",
    "display_image([img_tf.numpy(), edge_x.numpy(), edge_y.numpy(), edge_magnitude.numpy()],\n",
    "             titles=[\"Original Image\", \"Horizontal Edges\", \"Vertical Edges\", \"Edge Magnitude\"],\n",
    "             figsize=(20, 5),\n",
    "             cmaps=[None, 'gray', 'gray', 'gray_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(image):\n",
    "    \"\"\"\n",
    "    Perform min-max normalization on an image.\n",
    "    Scales values to range [0, 1].\n",
    "    \"\"\"\n",
    "    # Convert to float32 for calculations\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # Calculate min and max values\n",
    "    min_val = tf.reduce_min(image)\n",
    "    max_val = tf.reduce_max(image)\n",
    "\n",
    "    # Normalize to [0, 1] range\n",
    "    normalized = (image - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def standardize(image):\n",
    "    \"\"\"\n",
    "    Perform standardization of an image.\n",
    "    Centers the data around mean 0 with standard deviation 1.\n",
    "    \"\"\"\n",
    "    # Convert to float32 for calculations\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = tf.reduce_mean(image)\n",
    "    std = tf.math.reduce_std(image)\n",
    "\n",
    "    # Standardize \n",
    "    standardized = (image - mean) / std\n",
    "\n",
    "    return standardized\n",
    "\n",
    "# Function to print statistics about an image\n",
    "def print_image_stats(image, name):\n",
    "    \"\"\"Print basic statistics about an image.\"\"\"\n",
    "    print(f\"\\n{name} Statistics:\")\n",
    "    print(f\"Mean: {tf.reduce_mean(image):.3f}\")\n",
    "    print(f\"Std Dev: {tf.math.reduce_std(image):.3f}\")\n",
    "    print(f\"Min: {tf.reduce_min(image):.3f}\")\n",
    "    print(f\"Max: {tf.reduce_max(image):.3f}\")\n",
    "\n",
    "# Get original image statistics\n",
    "print_image_stats(tf.cast(img_tf, tf.float32), \"Original Image\")\n",
    "\n",
    "# Apply normalizations\n",
    "normalized_img = min_max_normalize(img_tf)\n",
    "standardized_img = standardize(img_tf)\n",
    "\n",
    "# Get statistics for processed images\n",
    "print_image_stats(normalized_img, \"Min-Max Normalized Image\")\n",
    "print_image_stats(standardized_img, \"Standardized Image\")\n",
    "\n",
    "# Function to visualize pixel value distributions\n",
    "def plot_distribution(image, title):\n",
    "    \"\"\"Plot histogram of pixel values.\"\"\"\n",
    "    values = tf.reshape(image, [-1]) # Flatten the image\n",
    "    plt.hist(values.numpy(), bins = 50)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "# Original image and its distribution\n",
    "plt.subplot(331)\n",
    "plt.imshow(cv2.cvtColor(img_tf.numpy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(334)\n",
    "plot_distribution(tf.cast(img_tf, tf.float32), \"Original Pixel Distribution\")\n",
    "\n",
    "# Min-max normalized image and its distribution\n",
    "plt.subplot(332)\n",
    "plt.imshow(cv2.cvtColor((normalized_img.numpy() * 255).astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Min-Max Normalized\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(335)\n",
    "plot_distribution(normalized_img, \"Min-Max Normalized Pixel Distribution\")\n",
    "\n",
    "# Standardized image and its distribution\n",
    "# For display, we need to rescale standardized values to 0-255 range\n",
    "standardized_display = (standardized_img - tf.reduce_min(standardized_img)) / (tf.reduce_max(standardized_img) - tf.reduce_min(standardized_img))\n",
    "\n",
    "plt.subplot(333)\n",
    "plt.imshow(cv2.cvtColor((standardized_display.numpy() * 255).astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Standardized\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(336)\n",
    "plot_distribution(standardized_img, \"Standardized Pixel Distribution\")\n",
    "\n",
    "# Add color channel distributions on the bottom row\n",
    "plt.subplot(337)\n",
    "for i, color in enumerate(['blue', 'green', 'red']):\n",
    "    values = tf.reshape(tf.cast(img_tf[..., i], tf.float32), [-1])\n",
    "    plt.hist(values.numpy(), bins=50, alpha=0.5, label=color, color=color)\n",
    "plt.title(\"Original Channel Distributions\")\n",
    "\n",
    "plt.subplot(338)\n",
    "for i, color in enumerate(['blue', 'green', 'red']):\n",
    "    values = tf.reshape(normalized_img[..., i], [-1])\n",
    "    plt.hist(values.numpy(), bins=50, alpha=0.5, label=color, color=color)\n",
    "plt.title(\"Normalized Channel Distributions\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(339)\n",
    "for i, color in enumerate(['blue', 'green', 'red']):\n",
    "    values = tf.reshape(standardized_img[..., i], [-1])\n",
    "    plt.hist(values.numpy(), bins=50, alpha=0.5, label=color, color=color)\n",
    "plt.title(\"Standardized Channel Distributions\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
